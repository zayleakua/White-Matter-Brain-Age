{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8tPvbVga18Y"
      },
      "source": [
        "# **Training, testing and evaluation of linear and nonlinear models for GM**\n",
        "@author: Ruijia & Zaylea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDfOnz0FVzUp"
      },
      "source": [
        "### **Linear models**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr, spearmanr  # ← ADD stats imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6xsTEWOTH3t",
        "outputId": "95c719a1-0069-45a2-ad8a-0e6371deccb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 17 rows with Age = 0 or NaN\n",
            "\n",
            "===== Training RidgeRegression =====\n",
            "Fold 1 Best Params: {'alpha': 100}, CV Score: 0.7196\n",
            "Fold 2 Best Params: {'alpha': 100}, CV Score: 0.6912\n",
            "Fold 3 Best Params: {'alpha': 100}, CV Score: 0.7591\n",
            "Fold 4 Best Params: {'alpha': 100}, CV Score: 0.7058\n",
            "Fold 5 Best Params: {'alpha': 100}, CV Score: 0.7430\n",
            "Selected best parameters for final training: {'alpha': 100}\n",
            "\n",
            "===== Training LassoRegression =====\n",
            "Fold 1 Best Params: {'alpha': 0.1}, CV Score: 0.6698\n",
            "Fold 2 Best Params: {'alpha': 1}, CV Score: 0.6669\n",
            "Fold 3 Best Params: {'alpha': 1}, CV Score: 0.7191\n",
            "Fold 4 Best Params: {'alpha': 1}, CV Score: 0.6820\n",
            "Fold 5 Best Params: {'alpha': 1}, CV Score: 0.6963\n",
            "Selected best parameters for final training: {'alpha': 1}\n",
            "\n",
            "===== Training ElasticNet =====\n",
            "Fold 1 Best Params: {'alpha': 1, 'l1_ratio': 0.1}, CV Score: 0.7397\n",
            "Fold 2 Best Params: {'alpha': 1, 'l1_ratio': 0.1}, CV Score: 0.7339\n",
            "Fold 3 Best Params: {'alpha': 1, 'l1_ratio': 0.1}, CV Score: 0.7807\n",
            "Fold 4 Best Params: {'alpha': 1, 'l1_ratio': 0.1}, CV Score: 0.7347\n",
            "Fold 5 Best Params: {'alpha': 1, 'l1_ratio': 0.1}, CV Score: 0.7767\n",
            "Selected best parameters for final training: {'alpha': 1, 'l1_ratio': 0.1}\n",
            "\n",
            "===== Final Model Performance on Independent Test Set =====\n",
            "RidgeRegression - MSE: 73.4698, MAE: 6.9047, R²: 0.7629, Mean Age Gap: 6.9047\n",
            "LassoRegression - MSE: 85.5902, MAE: 7.2404, R²: 0.7238, Mean Age Gap: 7.2404\n",
            "ElasticNet - MSE: 65.2934, MAE: 6.7547, R²: 0.7893, Mean Age Gap: 6.7547\n"
          ]
        }
      ],
      "source": [
        "# Set random seed\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv('a2009s_with_age_sex.csv')\n",
        "\n",
        "# Remove rows with missing or zero Age\n",
        "initial_rows = df.shape[0]\n",
        "df = df[df['Age'].notna()]\n",
        "df = df[df['Age'] != 0]\n",
        "print(f\"Removed {initial_rows - df.shape[0]} rows with Age = 0 or NaN\")\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop(columns=['CCID', 'Age'])\n",
        "y = df['Age'].values\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Define models and hyperparameter grids\n",
        "param_grids = {\n",
        "    \"RidgeRegression\": {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
        "    \"LassoRegression\": {'alpha': [0.01, 0.1, 1, 10, 100]},\n",
        "    \"ElasticNet\": {'alpha': [0.1, 1, 10, 100], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
        "\n",
        "}\n",
        "\n",
        "linear_models = {\n",
        "    \"RidgeRegression\": Ridge(random_state=RANDOM_SEED, max_iter=100000),\n",
        "    \"LassoRegression\": Lasso(random_state=RANDOM_SEED, max_iter=100000),\n",
        "    \"ElasticNet\": ElasticNet(random_state=RANDOM_SEED, max_iter=100000)\n",
        "}\n",
        "\n",
        "# Cross-validation for best hyperparameters + final model training\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "results = {}\n",
        "\n",
        "for model_name, model in linear_models.items():\n",
        "    print(f\"\\n===== Training {model_name} =====\")\n",
        "    fold_best_params = []\n",
        "    fold_best_scores = []\n",
        "\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "        grid_search = GridSearchCV(model, param_grids[model_name], cv=5)\n",
        "        grid_search.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "        fold_best_params.append(grid_search.best_params_)\n",
        "        fold_best_scores.append(grid_search.best_score_)\n",
        "\n",
        "        print(f\"Fold {fold_idx+1} Best Params: {grid_search.best_params_}, CV Score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    # Select best parameters based on highest score\n",
        "    best_index = np.argmax(fold_best_scores)\n",
        "    selected_best_param = fold_best_params[best_index]\n",
        "    print(f\"Selected best parameters for final training: {selected_best_param}\")\n",
        "\n",
        "    # Train final model on full training set with selected parameters\n",
        "    final_model = model.set_params(**selected_best_param)\n",
        "    final_model.fit(X_train, y_train)\n",
        "    y_pred = final_model.predict(X_test)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mean_age_gap = np.mean(np.abs(y_test - y_pred))\n",
        "    # Pearson PCC & Spearman SPCC\n",
        "    pcc, _ = pearsonr(y_test, y_pred)\n",
        "    spcc, _ = spearmanr(y_test, y_pred)\n",
        "\n",
        "    results[model_name] = {\n",
        "        'MSE': mse,\n",
        "        'MAE': mae,\n",
        "        'R²': r2,\n",
        "        'Mean_Age_Gap': mean_age_gap,\n",
        "        'PCC': pcc,\n",
        "        'SPCC': spcc\n",
        "    }\n",
        "\n",
        "# Print final evaluation results\n",
        "print(\"\\n===== Final Model Performance on Independent Test Set =====\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, MAE: {metrics['MAE']:.4f}, R²: {metrics['R²']:.4f}, Mean Age Gap: {metrics['Mean_Age_Gap']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbH062ArVvpy"
      },
      "source": [
        "### **Nonlinear models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr, spearmanr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIOflkuzJpXv",
        "outputId": "c615efa1-fbbd-46d1-f5c0-6a2ba3f843c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 17 rows with Age = 0 or NaN\n",
            "Model: RandomForest\n",
            "Fold 1 Best Params: {'n_estimators': 150, 'max_depth': 20}, CV Score: -9.3576\n",
            "Fold 2 Best Params: {'n_estimators': 150, 'max_depth': 20}, CV Score: -9.3380\n",
            "Fold 3 Best Params: {'n_estimators': 100, 'max_depth': 30}, CV Score: -9.2160\n",
            "Fold 4 Best Params: {'n_estimators': 150, 'max_depth': 20}, CV Score: -9.1335\n",
            "Fold 5 Best Params: {'n_estimators': 150, 'max_depth': 20}, CV Score: -8.9494\n",
            "Selected best parameters for final training: {'n_estimators': 150, 'max_depth': 20}\n",
            "Model: XGBoost\n",
            "Fold 1 Best Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, CV Score: -8.7096\n",
            "Fold 2 Best Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, CV Score: -8.5732\n",
            "Fold 3 Best Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, CV Score: -8.5439\n",
            "Fold 4 Best Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, CV Score: -8.3635\n",
            "Fold 5 Best Params: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}, CV Score: -8.2856\n",
            "Selected best parameters for final training: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1}\n",
            "\n",
            "Model Performance (5-Fold Cross-Validation):\n",
            "RandomForest - MSE: 110.0520, MAE: 8.2541, R²: 0.6449, Mean Age Gap: 8.2541, PCC: 0.8148, SPCC: 0.8168\n",
            "XGBoost - MSE: 103.4697, MAE: 7.8861, R²: 0.6661, Mean Age Gap: 7.8861, PCC: 0.8206, SPCC: 0.8202\n"
          ]
        }
      ],
      "source": [
        "# Set random seed\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv('a2009s_with_age_sex.csv')\n",
        "\n",
        "# Remove rows with missing or zero Age\n",
        "initial_rows = df.shape[0]\n",
        "df = df[df['Age'].notna()]\n",
        "df = df[df['Age'] != 0]\n",
        "print(f\"Removed {initial_rows - df.shape[0]} rows with Age = 0 or NaN\")\n",
        "\n",
        "# Select features (including Sex if categorical)\n",
        "X = df.drop(columns=['CCID', 'Age'])\n",
        "y = df['Age'].values\n",
        "\n",
        "# Encode sex if necessary\n",
        "if \"Sex\" in X.columns and (X['Sex'].dtype == object or X['Sex'].nunique() <= 3):\n",
        "    le = LabelEncoder()\n",
        "    X['Sex'] = le.fit_transform(X['Sex'])\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Define models and hyperparameter grids\n",
        "param_grids = {\n",
        "    \"RandomForest\": {'n_estimators': [50, 100, 150],\n",
        "                     'max_depth': [10, 20, 30]},\n",
        "    \"XGBoost\": {'n_estimators': [50, 100, 150],\n",
        "                'learning_rate': [0.05, 0.1, 0.2],\n",
        "                'max_depth': [3, 5, 7]}\n",
        "}\n",
        "\n",
        "nonlinear_models = {\n",
        "    \"RandomForest\": RandomForestRegressor(random_state=RANDOM_SEED),\n",
        "    \"XGBoost\": XGBRegressor(random_state=RANDOM_SEED, verbosity=0)\n",
        "}\n",
        "\n",
        "# Cross-validation setup\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
        "results = {}\n",
        "\n",
        "for model_name, model in nonlinear_models.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    fold_best_params = []\n",
        "    fold_best_scores = []\n",
        "\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "        X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "        search = RandomizedSearchCV(\n",
        "            model,\n",
        "            param_distributions=param_grids[model_name],\n",
        "            n_iter=5,\n",
        "            cv=3,\n",
        "            scoring='neg_mean_absolute_error',\n",
        "            n_jobs=-1,\n",
        "            random_state=RANDOM_SEED\n",
        "        )\n",
        "        search.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "        fold_best_params.append(search.best_params_)\n",
        "        fold_best_scores.append(search.best_score_)\n",
        "\n",
        "        print(f\"Fold {fold_idx+1} Best Params: {search.best_params_}, \"\n",
        "              f\"CV Score: {search.best_score_:.4f}\")\n",
        "\n",
        "    # Select best parameters based on highest CV score\n",
        "    best_index = np.argmax(fold_best_scores)\n",
        "    selected_best_param = fold_best_params[best_index]\n",
        "    print(f\"Selected best parameters for final training: {selected_best_param}\")\n",
        "\n",
        "    # Train final model on full training set with selected parameters\n",
        "    final_model = model.set_params(**selected_best_param)\n",
        "    final_model.fit(X_train, y_train)\n",
        "    y_pred = final_model.predict(X_test)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mean_age_gap = np.mean(np.abs(y_test - y_pred))\n",
        "    pcc, _ = pearsonr(y_test, y_pred)\n",
        "    spcc, _ = spearmanr(y_test, y_pred)\n",
        "\n",
        "    results[model_name] = {\n",
        "        'MSE': mse,\n",
        "        'MAE': mae,\n",
        "        'R²': r2,\n",
        "        'Mean_Age_Gap': mean_age_gap,\n",
        "        'PCC': pcc,\n",
        "        'SPCC': spcc\n",
        "    }\n",
        "\n",
        "# Print final evaluation results\n",
        "print(\"\\nModel Performance (5-Fold Cross-Validation):\")\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"{model_name} - MSE: {metrics['MSE']:.4f}, \"\n",
        "          f\"MAE: {metrics['MAE']:.4f}, \"\n",
        "          f\"R²: {metrics['R²']:.4f}, \"\n",
        "          f\"Mean Age Gap: {metrics['Mean_Age_Gap']:.4f}, \"\n",
        "          f\"PCC: {metrics['PCC']:.4f}, \"\n",
        "          f\"SPCC: {metrics['SPCC']:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
